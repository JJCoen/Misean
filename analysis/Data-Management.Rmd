---
title: "Donations Analysis"
type: inverse
subtitle: "Data management and analysis of Indian political party donations"
author: "Jim Coen"
date: "`r format(Sys.Date(), '%A, %B %d, %Y') `"
output:
  html_document: 
    toc: yes
    fig.width: 4
    fig_caption: yes
    number_sections: yes
    code_folding: hide
editor_options: 
  markdown: 
    wrap: 80
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = TRUE)
knitr::opts_chunk$set(echo = TRUE)
options(digits = 3)

# Helper packages
#install.packages("XLConnect")
library(XLConnect)  # Reading / Writing Excel Worksheets
library(tidyr)    # for tabular data
library(dplyr)    # for data manipulation
library(ggplot2)  # for awesome graphics
library(visdat)   # for additional visualizations
library(data.table) # primary data type for tabular data
library(kableExtra) # kable for printing tabular data
library(skimr)    # Detailed summary of features and values

# Feature engineering packages
library(tidyverse)  # data manipulation and visualization
library(readxl)   # get data out of Excel and into R
```

# Purpose

Pre-process data so that it is amenable to analysis. Specifically, generate the
tables needed for creating a Donations Dashboard displaying:

1.  Summary of data, showing comparisons.
2.  KPI: Donations Growth.
3.  KPI: Value of donations.
4.  KPI: Donor trend over time.

Save tables to separate sheets in Excel Workbook.

## **Characteristics of Clean Data and Messy Data**

What exactly is clean data? Clean data is accurate, complete, and in a format
that is ready to analyze. Characteristics of clean data include data that are:

-   Free of duplicate rows/values
-   Error-free (e.g. free of misspellings)
-   Relevant (e.g. free of special characters)
-   The appropriate data type for analysis
-   Free of outliers (or only contain outliers have been identified/understood),
    and
-   Follows a "tidy data" structure

Common symptoms of messy data include data that contain:

-   Special characters (e.g. commas in numeric values)
-   Numeric values stored as text/character data types
-   Duplicate rows
-   Misspellings
-   Inaccuracies
-   White space
-   Missing data
-   Zeros instead of null values

Source: [Dataquest](https://www.dataquest.io/blog/load-clean-data-r-tidyverse/)

## Primary Research Question

What are data management tasks and steps to perform for each task?

## Load Data

### Dataset

Donations to political parties from India, 12 Yrs data (2003-04 to 2014-15).
[Source:
data.world](https://data.world/ambarishn/donations-to-political-parties).

While there are some high value donations, most of the contributions are below
\$500,000. The Data Summary shows individual donations up to a value of
\$10,000,000. There are an additional 191 donations beyond that value. These are
not shown since they tend to skew the data.

Connect to Excel workbook and inspect names of sheets.

```{r, donate_book}
donate_book <- loadWorkbook("./data/donations-political-parties-India.xlsx")
getSheets(donate_book)
```

Store `Donation_data` sheet as a table.

```{r, load data, message=FALSE}
donations_dt <- read_excel("./data/donations-political-parties-India.xlsx", sheet ="Donation_data") %>% 
  as.data.table()
```

Remove columns having all missing entries and inspect the remaining columns.

```{r, skim}
donations_dt <- donations_dt[, c(1:8)]
glimpse(donations_dt)
```

# Pre-Processing

## 1. Column names

1.  Replace space between column names with underscore and convert to lower
    case.
2.  Print column names.

```{r, col names}
if (!require("stringr")) install.packages("stringr")
library("stringr")
names(donations_dt) <- str_replace_all(names(donations_dt), 
                                       "\\s", "_") %>% 
  tolower()
colnames(donations_dt)
```

## **2. Missing Entries**

The `contribution_mode` column has 234 missing entries and `address` has 1
missing. Replace these with \`unknown\` designation.

```{r, missings}
donations_dt[is.na(address), address := "unknown"]
donations_dt[is.na(contribution_mode), contribution_mode := "unknown"]
```

## 3. Type Conversion

### Convert financial_year to numeric

1.  Strip last three characters from financial_year.
2.  Convert single year from character to numeric.
3.  Order donations table by year ascending.

```{r, convert}
# Create new column named year
donations_dt[, year := str_sub(financial_year, end=-4)][, financial_year := NULL]
# Convert to numeric
donations_dt[, year := as.numeric(year)]                      
# Order data table by year
donations_dt <- donations_dt[order(year)]
```

### Convert year from numeric to categorical

```{r}
donations_dt[, year := as.factor(year)]
```

## 4. Check for outliers

```{r}
library(scales)   # to display values in thousands

# Basic scatter plot
ggplot(donations_dt, aes(x=year, y=amount)) + 
  geom_point() +
  labs(title="Individual donations",
       x="Year", 
       y = "Amount") +
  scale_y_continuous(label=comma ) 
```

$\rightarrow$ There are eleven contributions over \$100 Million out of 13,573
separate donations. Since these points skew the data, it is better to set the
limit for `amount` to \$100 Million when plotting data. However, it is necessary
to retain these contributions for the sake of accuracy.

# Key Performance Indicators

## Donations growth over time

Create a new table giving the total donations by year.

```{r, donate_year}

options("scipen"=100, "digits"=4)
donate_year <- donations_dt[, .(year_sum = sum(amount)), by = year ]
```

Visualise.

```{r}
# Donations Growth
g2 <- ggplot(donate_year, 
             aes(x=year, y = year_sum)) +
  geom_point(color = "blue") +
  labs(title="Total Amount per Year",
       x="Year", 
       y = "Annual Amount") +
  theme(legend.position="none") +
  # amount in thousands
  # scale_y_continuous(label=comma ) +
  # amount in Millions
	scale_y_continuous(labels = label_number(suffix = " M", 
	                                         scale = 1e-6),
	                   n.breaks=6) +  
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) +
  coord_flip()

g2
```

1.  Write donations by year table to Excel Workbook.
2.  Save updated Workbook

```{r, save donate_year}
createSheet(donate_book, name ="Donation_year")
writeWorksheet(donate_book, donate_year, sheet ="Donation_year")
```

## Donor Growth

Clean character strings in `name` column.

1.  Remove punctuation marks.
2.  Replace white-space with underscore

```{r, clean names}
# remove punctuation and replace whitespace with underscore
donations_dt$name <- str_replace_all(donations_dt$name, 
                pattern = "[[:punct:]]", 
                replacement = "") 
donations_dt$name <- str_replace_all(donations_dt$name, 
                pattern = "\\s", 
                replacement = "_") 
```

### Unique Donors

```{r, unique donors}
donations_dt[, unique(name)] %>% 
  length()
```

There are 10,807 unique donors out of 13,573 total donations given. So, most
donations are once-off.

1.  Create a new table showing total amount each donor contributed.
2.  Save table as a new Excel sheet in WorkBook.

```{r, by_donor}
by_donor <- donations_dt[, .(tot_amount = sum(amount)), by=name]

createSheet(donate_book, name ="Donation_donor")
writeWorksheet(donate_book, by_donor, sheet ="Donation_donor")
```

## Number of Donors

Number of donors making contributions per year.

```{r}
contributions <-  donations_dt[, .N, by = year]
contributions[, year := seq.int(from = 2003, to = 2014, 
                                by = 1)]
createSheet(donate_book, name ="Contributions")
writeWorksheet(donate_book, contributions, sheet ="Contributions")
```

## Store Data

1.  Save R tables in RData file.
2.  Write to Excel WorkBook file containing separate sheets for each new table.

```{r}
# Save RData
save(by_donor, donate_year, contributions, donations_dt, 
     file = "./data/donate.RData")

# Excel WorkBook
saveWorkbook(donate_book, file = "./data/donations-India-update.xlsx")
```

## Numeric Columns

### **Normalization**

Another common task is centering and scaling numeric variables, known as
normalization. For each numeric column, we subtract the mean and divide by the
standard deviation. This transforms numeric variables to standard deviation
units with a mean of 0 and standard deviation of 1. Interpreting normalized
variable values is very intuitive. From the normalized total_time value, we see
that spending 1,273 seconds on the website is 1-point-19 standard deviations
greater than the average time spent by customers.

## 
